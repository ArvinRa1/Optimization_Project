{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of O4DS_for_testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Improting libraries"
      ],
      "metadata": {
        "id": "3xh_4fUNVXq4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VjKQaghqn1jF"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math \n",
        "from cvxopt import matrix, solvers\n",
        "#from scipy.spatial import ConvexHull, convex_hull_plot_2d\n",
        "#from scipy.optimize import line_search\n",
        "#from datetime import datetime\n",
        "from time import process_time\n",
        "from scipy import linalg\n",
        "from scipy.linalg import null_space "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To perform the experiments you first call the 'create_functions', then you will feed 'objective' and 'gradient' to the functions of the optimization algorithms. Gradient and objective will be to function where the regularization term is specified when create_functions is called. So when called inside the opt algorithms they just need xt. "
      ],
      "metadata": {
        "id": "B8z896ufrtQt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create Functions, Objective, gradient"
      ],
      "metadata": {
        "id": "Wosv0KmfVkNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_functions(Q, c, N, regularization=0, alpha1=0, alpha2=0): # I don't remeber why those default values for alpha1 and 2\n",
        "    dim = N\n",
        "    al1_up = 2 / (6 * (1 + 10 ** (-9)))               # the rules for al1 and al2 have been taken from the paper \n",
        "    al2_up = 2 / 25                                   # of the max clique \n",
        "    if alpha1 < 0 or alpha1 > al1_up:\n",
        "        alpha1 = np.random.uniform(low=0, high=al1_up)\n",
        "    if alpha2 < 0 or alpha2 > al2_up:\n",
        "        alpha2 = np.random.uniform(low=0, high=al2_up)\n",
        "\n",
        "    def objective(x):\n",
        "        term = 0.0\n",
        "        eps = (10 ** (-9)) * np.ones(x.shape)\n",
        "        if regularization == 0:\n",
        "            term = 0.0\n",
        "        if regularization == 1:\n",
        "            term = 1 / 2 * math.sqrt(np.sum(x * x))\n",
        "        elif regularization == 2:\n",
        "            term = alpha1 * np.sum((x + eps) ** 3)\n",
        "        elif regularization == 3:\n",
        "            term = alpha2 * np.sum(np.exp(-5 * x) - 1)\n",
        "        obj = 1 / 2 * x.T @ (Q @ x) + term\n",
        "        return obj\n",
        "\n",
        "    def gradient(x): \n",
        "        gt = 0.0     \n",
        "        eps = (10 ** (-9)) * np.ones(x.shape) \n",
        "        if regularization == 0:\n",
        "            gt = 0.0\n",
        "        if regularization == 1:\n",
        "            gt = math.sqrt(np.sum(x))  ###########\n",
        "        elif regularization == 2:\n",
        "            gt = (alpha1 / 3) * np.sum((x + eps) ** 2)\n",
        "        elif regularization == 3:\n",
        "            gt = alpha2 * np.sum(np.exp(-5 * x))\n",
        "        gr = Q @ x - gt\n",
        "        return gr\n",
        "\n",
        "    return objective, gradient"
      ],
      "metadata": {
        "id": "urZYM40An88o"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below there are all the functions that are called inside the opt. alg. The arguments were specified in every function, but actually it is not necessary because every variable is declared inside the o. a. I leave these arguments so that each of those functions can be easily tested outside the function. But if everything works, you can consider to remove the arguments"
      ],
      "metadata": {
        "id": "CvZRYlVyydj2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#in the original code xt was defined like this, inside the class ConvexCombination\n",
        "def value(self):\n",
        "    return self.matrix.T @ self.weights # in our code this should be active_set.T @ weights\n",
        "\n",
        "#xt = active_set.value()\n",
        "\n",
        "#I don't know, maybe this can help you during the experiments "
      ],
      "metadata": {
        "id": "e7q6D89pVEux"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ConvexCombination"
      ],
      "metadata": {
        "id": "ETRWDi7EVtz1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvexCombination: ## This is the convex combination class for initializing the start_point_convcomb in the algorithms and also returning the caratheodory method\n",
        "    ## this line initilizes the convex combination and accepts ConvexCombination(simplex[start_indexes], start_indexes, start_weights) which are from the simplex descriptor class\n",
        "    ## Also start_indexes = np.arange(0, N) which N is the size of the vertices in the graph \n",
        "    ## w = np.random.rand(N),  This returns an array of random numbers of length N between 0 and 1\n",
        "    ## start_weights = w / sum(w) which N is the size of vertices in the graph \n",
        "    def __init__(self, points_matrix, vertex_indexes, weights=False): \n",
        "        self.matrix = np.array(points_matrix) ## Making a numpy array out of points_matrix (simplex[start_indexes])\n",
        "        self.indexes = np.array(vertex_indexes) ## Making a numpy array out of points_matrix (start_indexes)\n",
        "        ## if we do not have the start_weights we initiate them like this \n",
        "        if (type(weights) == bool): ## if we have a type bool we can say that it is the defualt value \n",
        "            l = points_matrix.shape[0] ## .shape[0] is the size of N \n",
        "            self.weights = 1 / l * np.ones(l) ## all the weights are ((one / N(or L) )) in an array of size L which is N  \n",
        "        else:\n",
        "            self.weights = np.array(weights) ## Else the wights are the weights \n",
        "\n",
        "    def copy(self):\n",
        "        return ConvexCombination(self.matrix, self.indexes, self.weights) # Intiate another object of class convexcombination\n",
        "\n",
        "    def value(self):\n",
        "        return self.matrix.T @ self.weights # we take the transpose of the matrix and the multiply it by the weights\n",
        "\n",
        "    def drop(self, index):\n",
        "        self.matrix = np.delete(self.matrix, index, 0)\n",
        "        self.indexes = np.delete(self.indexes, index)\n",
        "        self.weights = np.delete(self.weights, index)\n",
        "\n",
        "    def size(self):\n",
        "        return self.weights.shape[0]"
      ],
      "metadata": {
        "id": "fJ8g26dS9Xd9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SimplexDescriptor"
      ],
      "metadata": {
        "id": "egG46ip5V2zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimplexDescriptor():\n",
        "    def _get_column(self, k):\n",
        "        r = np.zeros(self.dim)\n",
        "        r[k] = 1\n",
        "        return r\n",
        "\n",
        "    def _change_column(self, r, i, k):\n",
        "        r[i, k] = 1\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        if (type(key) == tuple):\n",
        "            if (len(key) > 2):\n",
        "                raise IndexError(\"Too many indexes: %d > 2\" % len(key))\n",
        "            k1, k2 = key\n",
        "        else:\n",
        "            k1, k2 = key, slice(None, None, None)\n",
        "        if (type(k1) == int) or (type(k1) == np.int64):\n",
        "            r = self._get_column(k1)\n",
        "            return r[k2]\n",
        "        if (type(k1) == slice):\n",
        "            start, stop, step = k1.indices(self.vertices_numbers)\n",
        "            rlen = (stop - start - 1) // step + 1\n",
        "            indexes = list(range(start, stop, step))\n",
        "        else:\n",
        "            rlen = len(k1)\n",
        "            indexes = k1\n",
        "        i, r = 0, np.zeros([rlen, self.dim])\n",
        "        for x in indexes:\n",
        "            self._change_column(r, i, x)\n",
        "            i += 1\n",
        "        return r[:, k2]\n",
        "        # return r\n",
        "\n",
        "    def __init__(self, dimension):\n",
        "        self.dim = dimension\n",
        "        self.vertices_numbers = self.dim\n",
        "\n",
        "    def __matmul__(self, v):\n",
        "        if (len(v) != self.dim):\n",
        "            raise IndexError('Wrong dimension')\n",
        "        r = v[np.arange(0, self.dim)]\n",
        "        return r"
      ],
      "metadata": {
        "id": "CxXcPDTC9XoC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lipk and sz"
      ],
      "metadata": {
        "id": "I-1-mKSPV7is"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def shrink_active_set(active_set, weights):\n",
        "    zero_threshold = 1e-12\n",
        "    w = weights\n",
        "    l = weights.shape[0]\n",
        "    zero_weights = np.where(np.abs(w) <= zero_threshold/l)\n",
        "    if zero_weights[0].size:\n",
        "        weights = np.delete(weights, weights[zero_weights])\n",
        "        active_set = np.delete(active_set, active_set[zero_weights])\n",
        "    return active_set, weights\n",
        "\n",
        "def get_auxiliary_stepsize(Q, x_t, y_j, g, d, L=1e-2):\n",
        "    if np.linalg.norm(y_j-(x_t + g / 2 / L)) < np.linalg.norm(g) / 2 / L and np.linalg.norm(y_j - x_t) < g@d/L:\n",
        "        return gradient(y_j)@d/L/np.linalg.norm(d)\n",
        "    else:\n",
        "        return 0\n",
        "# vertices are N= simplex\n",
        "def LMO(simplex, gradient_xt): \n",
        "    sti = np.argmin(simplex @ gradient_xt) ## the gradient(xt)\n",
        "    st = simplex[sti] # simplex[sti] only thing left to be defined is simplex\n",
        "    return st, sti\n",
        "\n",
        "\n",
        "def lipk_and_sz(Q, x_t, f_x, g, gamma_max, d_t, x0, L):\n",
        "    \n",
        "    if type(x0) == int:\n",
        "        x0 = x_t \n",
        "        ##print(\"x0:\", x0)\n",
        "    epsilon = 10e-3\n",
        "    k1 = 0.9\n",
        "    k2 = 2\n",
        "    nL = k1 * L\n",
        "    clip = g ** 2 / (2 * (objective(x0) - f_x) * d_t.T @ d_t)\n",
        "    ##print(\"print clip: \", clip) ## clip should not be zero\n",
        "    M = np.clip(clip ,nL, L) ## the function clip is bounded by upper bound nL and lower bound L\n",
        "    ##print(\"M:\", M)\n",
        "    gamma = min(g / (M * d_t.T @ d_t), gamma_max)\n",
        "    ##print(\"gamma:\", gamma)\n",
        "    while objective(x_t + (gamma * d_t)) > (f_x - (gamma * g) + (g * (gamma ** 2) * M) / (d_t.T @ d_t)) :\n",
        "        M = k2 * M\n",
        "        ##print(\"Updating M:\", M)\n",
        "        gamma = min(g/(M*d_t.T@d_t), gamma_max)\n",
        "    return gamma, M\n"
      ],
      "metadata": {
        "id": "qcwUelXgsRwM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FW Away step with Lipschiz Step"
      ],
      "metadata": {
        "id": "yI3H5kMkWBlJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#gradient, objective = create_functions(Q, c, N)\n",
        "# I think you can remove fx and gradient as arguments\n",
        "def FW_AS_our(objective,  gradient, Q, N, active_set = None, max_iter = 1000):\n",
        "    FW_AS_our.label = FW_AS_our\n",
        "    eps = 1e-6\n",
        "    xt  = active_set.value()\n",
        "    weights = active_set.weights\n",
        "    #print(\"Do we get here?\")\n",
        "    for i in range(max_iter):\n",
        "        if i==0:\n",
        "            x0 = 1\n",
        "            L = 1\n",
        "        fxt = objective(xt)\n",
        "        #print(\" I wonder if we get here\")  ## We do \n",
        "        st, sti = LMO(N, gradient(xt)) #defined\n",
        "        #print(\" I wonder if we get here\")  ## We do \n",
        "        dfw = st - xt\n",
        "        vt = np.max(active_set.matrix @gradient(xt)) # feed to the function the proprer value for active set \n",
        "        vti = np.argmax(active_set.matrix @gradient(xt)) # gradient is a fucntion itself\n",
        "        daw = xt - vt\n",
        "        gfw =  - gradient(xt)@dfw\n",
        "        #print(\" I wonder if we get here\")  ## We do \n",
        "        if  gfw  <= eps: #check the sign of the gradient (or the sign of the gap)\n",
        "            return [xt, active_set, fxt, \"FW_AS\"]\n",
        "        if gfw >= gradient(xt) @ daw:\n",
        "            gamma_max=1\n",
        "            #print(\" I wonder if we get here\")\n",
        "            ##Q, x_t, f_x, g, gamma_max, d_t, x0=0, L=0\n",
        "            gamma, L = lipk_and_sz(Q, xt, fxt, gfw, gamma_max, dfw, x0, L) # we should change L=1 with L and x0=[] with x0\n",
        "            #print(\"How about HERE\")\n",
        "            x0 = xt # this is required by the the function lipk_and_sz, because at every call of this function we need to feed xt and xt-1\n",
        "            xt += gamma * dfw\n",
        "            weights = (1-gamma) * weights\n",
        "            weights[sti] += gamma #problem? #this shouldn't be a problem because weights'd be a matrix and in this way you'd update one row\n",
        "            if (gamma == 1):\n",
        "                active_set = st\n",
        "                weights = weights[sti]\n",
        "              \n",
        "            else:\n",
        "              active_set.matrix = np.vstack((active_set.matrix, st))\n",
        "              active_set.weights = np.hstack((active_set.weights, gamma))\n",
        "          \n",
        "        else:\n",
        "            weight_v_t = weights[vti]\n",
        "            gamma_max = weight_v_t / (1 - weight_v_t) # in this case the weights should not be one. if the weights are equal to one then gamma-max is \n",
        "            ## equal to one as well\n",
        "            ## def lipk_and_sz(Q, x_t, f_x, g, gamma_max, d_t, x0, L):\n",
        "            gamma, L = lipk_and_sz(Q, xt, fx, gaw, gamma_max, daw,  x0, L) # we should change L=0 with L and x0=0 with x0\n",
        "            x0 = xt # this is required by the the function lipk_and_sz, because at every call of this function we need to feed xt and xt-1\n",
        "            xt += gamma*daw\n",
        "            weights = (1+gamma) * weights\n",
        "            weights[vti] -= gamma #problem? #this shouldn't be a problem because weights'd be a matrix and in this way you'd update one row\n",
        "        if gamma == gamma_max:\n",
        "            active_set = np.delete(active_set, active_set[vti], 0) #active_set.drop(vt)\n",
        "            weights = np.delete(weights, weight_v_t)\n",
        "    shrink_active_set(active_set, weights) #define again \n",
        "    return [xt, active_set, fxt, \"FW_AS\"] \n",
        "\n"
      ],
      "metadata": {
        "id": "41YWZl6nt9TO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Set"
      ],
      "metadata": {
        "id": "jAVWilEiWQS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "_kJE2pUf9X0h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd7f5e8e-95c6-409d-c6ae-d19d635a48ae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dimacs_dir_path = \"/content/drive/MyDrive/Dimacs/dimacs/\"\n",
        "to_be_tested = \"/content/drive/MyDrive/Dimacs/dimacs/to_be_tested\""
      ],
      "metadata": {
        "id": "TdpD-UOs9X7H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check Clique"
      ],
      "metadata": {
        "id": "Z6QF2OqpWUqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def check_clique(Q, x):\n",
        "    print(x)\n",
        "    findx, = np.where(abs(x)>1e-3)\n",
        "    print(findx)\n",
        "    c = findx.size\n",
        "    v = abs(sum(sum(Q[findx][:, findx])) + c*(2*(c-1)+1))\n",
        "    print(\"Check clique:\", c, v)\n",
        "    return v<0.1, c\n"
      ],
      "metadata": {
        "id": "jSmQUrlX9X_c"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Part"
      ],
      "metadata": {
        "id": "oHbVnMonWX7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = {}\n",
        "algo_list = []\n",
        "#objective,  gradient, xt, Q, N, weights = np.array([]), active_set = None, max_iter = 1000\n",
        "options = {\"verbosity\": 0, \"epsilon\": 1e-6}\n",
        "# algo_list.append(FW_AwayStep_ClassicLipschizStep_Algorithm(**options))\n",
        "# algo_list.append(FW_Pairwise_ClassicLipschizStep_Algorithm(**options))\n",
        "algo_list.append(FW_AS_our)  #####################\n",
        "#algo_list.append(FW_Pairwise_ClassicArmijoStep_Algorithm(**options))  ####################\n",
        "#for A in algo_list:\n",
        "#    A.set_line_search_parameters()\n",
        "#algo_list.append(FW_AwayStep_SSC_Algorithm(**options))\n",
        "#algo_list.append(FW_Pairwise_SSC_Algorithm(**options))\n",
        "# =============================================================\n",
        "#algo_names = []\n",
        "#for algo in algo_list:\n",
        "#    algo_names.append(algo.label)\n",
        "# =============================================================\n",
        "np.set_printoptions(threshold=100)\n",
        "\n",
        "# ================================================================\n",
        "# This part is for preprocessing the graphs given to matrices \n",
        "def load_dimacs_graph(name):\n",
        "    t0 = process_time()\n",
        "    f = open(dimacs_dir_path + name, 'r') \n",
        "    edges = []\n",
        "    N, M, m, n = 0, 0, 0, 0\n",
        "    t1 = process_time()\n",
        "    rows = f.readlines()\n",
        "    t2 = process_time()\n",
        "    for row in rows:\n",
        "        args = row.split()\n",
        "        if (not N):\n",
        "            # if (match):\n",
        "            if (len(args) >= 4) and (args[0] == \"p\"):\n",
        "                # n, m = int(match.group(1)), int(match.group(2))\n",
        "                n, m = int(args[2]), int(args[3])\n",
        "                N = max(N, n)\n",
        "                M = m\n",
        "        if (len(args) >= 3) and (args[0] == \"e\"):\n",
        "            # v1, v2 = int(match.group(1)), int(match.group(2))\n",
        "            v1, v2 = int(args[1]), int(args[2])\n",
        "            edges.append((v1, v2))\n",
        "            N = max(N, v1, v2)\n",
        "    print(\"Caricamento %s: Controllo caricamento\" % name, (n == N), (m == M), (M == len(edges)))\n",
        "    t3 = process_time()\n",
        "    Q = -np.eye(N)\n",
        "    for v1, v2 in edges:\n",
        "        Q[v1 - 1, v2 - 1] = -2\n",
        "        Q[v2 - 1, v1 - 1] = -2\n",
        "    del row, edges\n",
        "    c = np.zeros(N)\n",
        "    t4 = process_time()\n",
        "    return Q, c, N, M, (t0, t1, t2, t3, t4)\n",
        "\n",
        "\"\"\"\n",
        "# ====================================================================================================================\n",
        "\n",
        "def check_clique(Q, x):\n",
        "    findx, = np.where(abs(x) > 1e-3)\n",
        "    print(findx)\n",
        "    c = findx.size\n",
        "    v = abs(sum(sum(Q[findx][:, findx])) + c * (2 * (c - 1) + 1))\n",
        "    print(\"Check clique:\", c, v)\n",
        "    return v < 0.1, c\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "# This part is where we define objective functions and gradients \n",
        "# If we want to use this optimization algorithms for other continuous optimization problems we have to change this part \n",
        "def create_functions(Q, c, N, regularization=0, alpha1=0, alpha2=0): # I don't remeber why those default values for alpha1 and 2\n",
        "    dim = N\n",
        "    al1_up = 2 / (6 * (1 + 10 ** (-9)))               # the rules for al1 and al2 have been taken from the paper \n",
        "    al2_up = 2 / 25                                   # of the max clique \n",
        "    if alpha1 < 0 or alpha1 > al1_up:\n",
        "        alpha1 = np.random.uniform(low=0, high=al1_up)\n",
        "    if alpha2 < 0 or alpha2 > al2_up:\n",
        "        alpha2 = np.random.uniform(low=0, high=al2_up)\n",
        "\n",
        "    def objective(x):\n",
        "        term = 0.0\n",
        "        eps = (10 ** (-9)) * np.ones(x.shape)\n",
        "        if regularization == 0:\n",
        "            term = 0.0\n",
        "        if regularization == 1:\n",
        "            term = 1 / 2 * math.sqrt(np.sum(x * x))\n",
        "        elif regularization == 2:\n",
        "            term = alpha1 * np.sum((x + eps) ** 3)\n",
        "        elif regularization == 3:\n",
        "            term = alpha2 * np.sum(np.exp(-5 * x) - 1)\n",
        "        obj = 1 / 2 * x.T @ (Q @ x) + term\n",
        "        return obj\n",
        "\n",
        "    def gradient(x): \n",
        "        gt = 0.0     \n",
        "        eps = (10 ** (-9)) * np.ones(x.shape) \n",
        "        if regularization == 0:\n",
        "            gt = 0.0\n",
        "        if regularization == 1:\n",
        "            gt = math.sqrt(np.sum(x))  ###########\n",
        "        elif regularization == 2:\n",
        "            gt = (alpha1 / 3) * np.sum((x + eps) ** 2)\n",
        "        elif regularization == 3:\n",
        "            gt = alpha2 * np.sum(np.exp(-5 * x))\n",
        "        gr = Q @ x - gt\n",
        "        return gr\n",
        "\n",
        "    return objective, gradient\n",
        "\"\"\"\n",
        "\n",
        "reg_list = [\"phiB\", \"phi1\", \"phi2\"]\n",
        "# ==================================================\n",
        "# This part of the code is for testing\n",
        "test_name_list_file = open(to_be_tested)\n",
        "test_name_list = test_name_list_file.read().split()\n",
        "test_name_list_file.close()\n",
        "print(\"Test list: \", test_name_list[:3])\n",
        "test_results = {}\n",
        "test_results_reg = {}\n",
        "error_list = []\n",
        "times = {ALG: [] for ALG in algo_list}\n",
        "clique_nums = {ALG: [] for ALG in algo_list}\n",
        "for test_name in test_name_list[:3]:  # \n",
        "    if (test_name[0] == \"#\"):\n",
        "        continue\n",
        "    print(\"*\" * 30 + \"\\nRunning test %s\\n\" % test_name + \"*\" * 30)\n",
        "    Q, c, N, M, times = load_dimacs_graph(test_name + \".clq\")\n",
        "    simplex = SimplexDescriptor(N) # Ke betavanim baadan parameter be algorithm ezafe konim\n",
        "    # ==============================================================================\n",
        "    for reg in range(1, 3):  # for faster runs change to range(1,3)\n",
        "        print(\"regularization_term: \", reg_list[reg])\n",
        "        objective, gradient = create_functions(Q, c, N, regularization=reg + 1)\n",
        "        # ===================================================================================\n",
        "        times = {ALG: [] for ALG in algo_list}\n",
        "        clique_nums = {ALG: [] for ALG in algo_list}\n",
        "        iteration_nums = {ALG: [] for ALG in algo_list}\n",
        "        for i in range(0, 10):\n",
        "            print(\"===\\nExecution #%02d\\n===\" % i)\n",
        "            np.random.seed(i)\n",
        "            w = np.random.rand(N)\n",
        "            start_weights = w / sum(w)\n",
        "            start_indexes = np.arange(0, N)\n",
        "            ##==========================================================\n",
        "            for ALG in algo_list:\n",
        "                #ALG.set_parameters(N, simplex)\n",
        "                #ALG.set_objective(objective, gradient, start_point=simplex[N - 1], alpha=1)  # alpha = 2 * LipschitzDFLowerBound)\n",
        "                x0 = ConvexCombination(simplex[start_indexes], start_indexes, start_weights)\n",
        "                t0 = process_time()\n",
        "                #ALG.run(max_iter=10000, start_point_convcomb=x0)\n",
        "                #objective,  gradient, Q, N, active_set = None, max_iter = 1000\n",
        "                x, cv, fx, status = ALG(objective, gradient, Q, simplex, x0, max_iter = 10000)\n",
        "                t1 = process_time()\n",
        "                delta_t = t1 - t0\n",
        "                #ALG.result\n",
        "                #iterations = ALG.t\n",
        "                check, cliq_num = check_clique(Q, x)\n",
        "                if (check):\n",
        "                    print(\"Is correct\")\n",
        "                else:\n",
        "                    print(\"Is NOT correct\")\n",
        "                    error_list.append((test_name, i, x, check, cliq_num))\n",
        "                print(x, fx, \"\\n\")\n",
        "                times[ALG].append(delta_t)\n",
        "                clique_nums[ALG].append(cliq_num)\n",
        "                #iteration_nums[ALG].append(iterations)\n",
        "            ##==========================================================\n",
        "        for ALG in algo_list:\n",
        "            print(ALG)\n",
        "            print(clique_nums[ALG], sum(clique_nums[ALG]) / 10)\n",
        "            print(times[ALG], sum(times[ALG]) / 10)\n",
        "            print(iteration_nums[ALG], sum(iteration_nums[ALG]) / 10)\n",
        "        test_results[test_name] = {\"cpu_time\": times, \"clique_number\": clique_nums, \"iteration_number\": iteration_nums}\n",
        "        test_results_reg[reg_list[reg]] = test_results\n",
        "\n",
        "# output_to_json()\n",
        "# ==================================================\n",
        "# This is the part we run to show different cpu times in different algorithms and compare results \n",
        "table_latex = \"\"\n",
        "test_table = []\n",
        "test_table_better = []\n",
        "test_table_better_reg = []\n",
        "test_names = []\n",
        "for test_name in test_results:\n",
        "    for regular in test_results_reg:\n",
        "        print(\"test_name: \", test_name)\n",
        "        print(regular)\n",
        "        result = test_results[test_name]\n",
        "        data_to_show_str = [test_name.replace(\"_\", \"\\\\_\")]\n",
        "        data_to_show = []  # test_name]\n",
        "        data_to_show_better = []\n",
        "        test_name_reg = test_name + \" \" + regular\n",
        "        test_names.append(test_name_reg)\n",
        "        for alg_label in result[\"clique_number\"]:\n",
        "            p = 4\n",
        "            d = []\n",
        "            clique_number = np.array(result[\"clique_number\"][alg_label])\n",
        "            cpu_time = np.array(result[\"cpu_time\"][alg_label])\n",
        "            v = [\n",
        "                min(clique_number),\n",
        "                np.mean(clique_number),\n",
        "                max(clique_number),\n",
        "                np.std(clique_number),\n",
        "                min(cpu_time),\n",
        "                np.mean(cpu_time),\n",
        "                max(cpu_time),\n",
        "                np.std(cpu_time)\n",
        "            ]\n",
        "            vbetter = [min(clique_number),\n",
        "                       np.mean(clique_number),\n",
        "                       max(clique_number),\n",
        "                       np.std(clique_number),\n",
        "                       np.mean(cpu_time)\n",
        "                       ]\n",
        "            d[0:2] = [str(v[0]), \"%.1f\" % v[1], str(v[2])]\n",
        "            d[3:8] = [\"%.2f\" % l for l in v[3:8]]\n",
        "            data_to_show_better += vbetter\n",
        "            data_to_show += v\n",
        "            data_to_show_str += d\n",
        "        # print(v, d)\n",
        "        test_table_better.append(data_to_show_better)\n",
        "        test_table.append(data_to_show)\n",
        "        table_latex += \" & \".join(data_to_show_str) + \" \\\\\\\\\\n\"\n",
        "    # test_table_better_reg.append\n",
        "print(len(test_table_better))\n",
        "clmsbetter = ['min clique number', 'mean clique number', 'max clique number', 'std clique number',\n",
        "              'mean cpu time']\n",
        "print(test_results_reg)\n",
        "muxbetter = pd.MultiIndex.from_product([algo_names, clmsbetter])\n",
        "df = pd.DataFrame(test_table_better, index=test_names, columns=muxbetter)\n",
        "with open('test_reg.txt', 'w') as f:\n",
        "    f.write(df.to_string())\n",
        "display(df)\n"
      ],
      "metadata": {
        "id": "jU2YYBVL9YHO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9829ecfd-2e0a-423c-9532-68a930bf4ad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test list:  ['brock200_2', 'brock200_4', 'brock400_2']\n",
            "******************************\n",
            "Running test brock200_2\n",
            "******************************\n",
            "Caricamento brock200_2.clq: Controllo caricamento True True True\n",
            "regularization_term:  phi1\n",
            "===\n",
            "Execution #00\n",
            "===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: divide by zero encountered in double_scalars\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3.49920115e-05 4.56000342e-05 3.84318222e-05 ... 1.62176129e-05\n",
            " 3.69990358e-06 1.10260068e-01]\n",
            "[  9  31  40  48  68  69  91 133 199]\n",
            "Check clique: 9 0.0\n",
            "Is correct\n",
            "[3.49920115e-05 4.56000342e-05 3.84318222e-05 ... 1.62176129e-05\n",
            " 3.69990358e-06 1.10260068e-01] -0.939347557459073 \n",
            "\n",
            "===\n",
            "Execution #01\n",
            "===\n",
            "[2.81347428e-05 4.85973021e-05 7.71639393e-09 ... 1.58114367e-05\n",
            " 4.16114743e-05 6.40261899e-05]\n",
            "[  9  45  69  88 105 135 157 160]\n",
            "Check clique: 8 0.0\n",
            "Is correct\n",
            "[2.81347428e-05 4.85973021e-05 7.71639393e-09 ... 1.58114367e-05\n",
            " 4.16114743e-05 6.40261899e-05] -0.9325294084696105 \n",
            "\n",
            "===\n",
            "Execution #02\n",
            "===\n",
            "[3.04967505e-05 1.81347493e-06 3.84475125e-05 ... 1.23869223e-01\n",
            " 6.41218891e-05 4.91216232e-05]\n",
            "[  9  40  69 105 160 184 196 197]\n",
            "Check clique: 8 0.0\n",
            "Is correct\n",
            "[3.04967505e-05 1.81347493e-06 3.84475125e-05 ... 1.23869223e-01\n",
            " 6.41218891e-05 4.91216232e-05] -0.9325262350270395 \n",
            "\n",
            "===\n",
            "Execution #03\n",
            "===\n",
            "[3.64411984e-05 4.68515859e-05 1.92464736e-05 ... 4.12045668e-06\n",
            " 5.85020699e-05 2.94951326e-05]\n",
            "[ 48  57  93 108 116 146 180 184]\n",
            "Check clique: 8 0.0\n",
            "Is correct\n",
            "[3.64411984e-05 4.68515859e-05 1.92464736e-05 ... 4.12045668e-06\n",
            " 5.85020699e-05 2.94951326e-05] -0.9325279262210979 \n",
            "\n",
            "===\n",
            "Execution #04\n",
            "===\n",
            "[5.95415513e-05 3.36939521e-05 5.98897091e-05 ... 5.45606812e-05\n",
            " 5.29919379e-05 1.01665829e-05]\n",
            "[ 28  43  57  93 108 112 133]\n",
            "Check clique: 7 0.0\n",
            "Is correct\n",
            "[5.95415513e-05 3.36939521e-05 5.98897091e-05 ... 5.45606812e-05\n",
            " 5.29919379e-05 1.01665829e-05] -0.9237589088538152 \n",
            "\n",
            "===\n",
            "Execution #05\n",
            "===\n",
            "[1.43049284e-05 5.61087679e-05 1.33206923e-05 ... 1.09702132e-01\n",
            " 1.58281169e-05 4.59228001e-06]\n",
            "[ 27  45  48  60 107 109 112 178 197]\n",
            "Check clique: 9 0.0\n",
            "Is correct\n",
            "[1.43049284e-05 5.61087679e-05 1.33206923e-05 ... 1.09702132e-01\n",
            " 1.58281169e-05 4.59228001e-06] -0.9393479332582083 \n",
            "\n",
            "===\n",
            "Execution #06\n",
            "===\n",
            "[5.91838313e-05 2.20055030e-05 5.44357207e-05 ... 4.25469034e-05\n",
            " 4.27318861e-05 4.50909103e-05]\n",
            "[  9  21  93 114 157 165 172 180]\n",
            "Check clique: 8 0.0\n",
            "Is correct\n",
            "[5.91838313e-05 2.20055030e-05 5.44357207e-05 ... 4.25469034e-05\n",
            " 4.27318861e-05 4.50909103e-05] -0.9325266640423193 \n",
            "\n",
            "===\n",
            "Execution #07\n",
            "===\n",
            "[5.18312807e-06 5.29748342e-05 2.97783008e-05 ... 2.59815052e-05\n",
            " 4.41590083e-05 4.04566861e-05]\n",
            "[ 21  31  40  43 114 165 196]\n",
            "Check clique: 7 0.0\n",
            "Is correct\n",
            "[5.18312807e-06 5.29748342e-05 2.97783008e-05 ... 2.59815052e-05\n",
            " 4.41590083e-05 4.04566861e-05] -0.9237590493043486 \n",
            "\n",
            "===\n",
            "Execution #08\n",
            "===\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "biOD6RQE9YOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "FBxJuJ3H9YR8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}